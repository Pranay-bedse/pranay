{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4f6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f814c50",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.environ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ec40aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6820b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = get_completion(\"What is the capital of France?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1c576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a95cf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7572eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "#response = get_completion_from_messages(messages, temperature=1)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe088e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550875d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdf9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dde15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09e4903",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f8d209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key  = os.environ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40a97be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "568a3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "system_message = f\"\"\"\n",
    "You will be provided with customer service queries. \\\n",
    "The customer service query will be delimited with \\\n",
    "{delimiter} characters.\n",
    "Classify each query into a primary category \\\n",
    "and a secondary category. \n",
    "Provide your output in json format with the \\\n",
    "keys: primary and secondary.\n",
    "\n",
    "Primary categories: Billing, Technical Support, \\\n",
    "Account Management, or General Inquiry.\n",
    "\n",
    "Billing secondary categories:\n",
    "Unsubscribe or upgrade\n",
    "Add a payment method\n",
    "Explanation for charge\n",
    "Dispute a charge\n",
    "\n",
    "Technical Support secondary categories:\n",
    "General troubleshooting\n",
    "Device compatibility\n",
    "Software updates\n",
    "\n",
    "Account Management secondary categories:\n",
    "Password reset\n",
    "Update personal information\n",
    "Close account\n",
    "Account security\n",
    "\n",
    "General Inquiry secondary categories:\n",
    "Product information\n",
    "Pricing\n",
    "Feedback\n",
    "Speak to a human\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a3a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = f\"\"\"\\\n",
    "I want you to delete my profile and all of my user data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d2bc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a257706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_completion_from_messages(messages)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaea47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a7cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca4944b0",
   "metadata": {},
   "source": [
    "# Promt Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37f1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb1eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0966d",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d89cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"\n",
    "# Summarize the text delimited by triple backticks \\ \n",
    "# into a single sentence.\n",
    "# ```{text}```\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e03130",
   "metadata": {},
   "source": [
    "#### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de64f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"\n",
    "# Generate a list of three made-up book titles along \\ \n",
    "# with their authors and genres. \n",
    "# Provide them in JSON format with the following keys: \n",
    "# book_id, title, author, genre.\n",
    "# \"\"\"\n",
    "# response = get_completion(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb009",
   "metadata": {},
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e61cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"\n",
    "# You will be provided with text delimited by triple quotes. \n",
    "# If it contains a sequence of instructions, \\ \n",
    "# re-write those instructions in the following format:\n",
    "\n",
    "# Step 1 - ...\n",
    "# Step 2 - …\n",
    "# …\n",
    "# Step N - …\n",
    "\n",
    "# If the text does not contain a sequence of instructions, \\ \n",
    "# then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "# \\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d1a3b",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" promptingm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b529826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992c9f0d",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45933e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2d6e",
   "metadata": {},
   "source": [
    "#### Ask for output in a specified format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_2 = f\"\"\"\n",
    "# Your task is to perform the following actions: \n",
    "# 1 - Summarize the following text delimited by \n",
    "#   <> with 1 sentence.\n",
    "# 2 - Translate the summary into French.\n",
    "# 3 - List each name in the French summary.\n",
    "# 4 - Output a json object that contains the \n",
    "#   following keys: french_summary, num_names.\n",
    "\n",
    "# Use the following format:\n",
    "# Text: <text to summarize>\n",
    "# Summary: <summary>\n",
    "# Translation: <summary translation>\n",
    "# Names: <list of names in Italian summary>\n",
    "# Output JSON: <json with summary and num_names>\n",
    "\n",
    "# Text: <{text}>\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a070c0",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacd4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"\n",
    "# Your task is to determine if the student's solution \\\n",
    "# is correct or not.\n",
    "# To solve the problem do the following:\n",
    "# - First, work out your own solution to the problem. \n",
    "# - Then compare your solution to the student's solution \\ \n",
    "# and evaluate if the student's solution is correct or not. \n",
    "# Don't decide if the student's solution is correct until \n",
    "# you have done the problem yourself.\n",
    "\n",
    "# Use the following format:\n",
    "# Question:\n",
    "# ```\n",
    "# question here\n",
    "# ```\n",
    "# Student's solution:\n",
    "# ```\n",
    "# student's solution here\n",
    "# ```\n",
    "# Actual solution:\n",
    "# ```\n",
    "# steps to work out the solution and your solution here\n",
    "# ```\n",
    "# Is the student's solution the same as actual solution \\\n",
    "# just calculated:\n",
    "# ```\n",
    "# yes or no\n",
    "# ```\n",
    "# Student grade:\n",
    "# ```\n",
    "# correct or incorrect\n",
    "# ```\n",
    "\n",
    "# Question:\n",
    "# ```\n",
    "# I'm building a solar power installation and I need help \\\n",
    "# working out the financials. \n",
    "# - Land costs $100 / square foot\n",
    "# - I can buy solar panels for $250 / square foot\n",
    "# - I negotiated a contract for maintenance that will cost \\\n",
    "# me a flat $100k per year, and an additional $10 / square \\\n",
    "# foot\n",
    "# What is the total cost for the first year of operations \\\n",
    "# as a function of the number of square feet.\n",
    "# ``` \n",
    "# Student's solution:\n",
    "# ```\n",
    "# Let x be the size of the installation in square feet.\n",
    "# Costs:\n",
    "# 1. Land cost: 100x\n",
    "# 2. Solar panel cost: 250x\n",
    "# 3. Maintenance cost: 100,000 + 100x\n",
    "# Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "# ```\n",
    "# Actual solution:\n",
    "# \"\"\"\n",
    "# response = get_completion(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941259d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
